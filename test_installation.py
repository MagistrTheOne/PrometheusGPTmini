#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PrometheusGPT Mini
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""

import sys
import torch
import numpy as np
from config import ModelConfig
from src.model import PrometheusGPT, count_parameters
from src.tokenizer import MultilingualTokenizer
from src.data import MultilingualDataset
from src.evaluator import ModelEvaluator


def test_imports():
    """–¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–æ–≤"""
    print("Testing imports...")
    try:
        import torch
        import transformers
        import datasets
        import tokenizers
        import sentencepiece
        print("‚úì All imports successful")
        return True
    except ImportError as e:
        print(f"‚úó Import failed: {e}")
        return False


def test_config():
    """–¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    print("\nTesting configuration...")
    try:
        config = ModelConfig()
        config.print_config()
        print("‚úì Configuration loaded successfully")
        return True
    except Exception as e:
        print(f"‚úó Configuration failed: {e}")
        return False


def test_model():
    """–¢–µ—Å—Ç –º–æ–¥–µ–ª–∏"""
    print("\nTesting model architecture...")
    try:
        config = ModelConfig()
        model = PrometheusGPT(config)

        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = count_parameters(model)
        print(f"‚úì Model created with {total_params:,} parameters")

        # –¢–µ—Å—Ç forward pass
        batch_size, seq_len = 2, 16
        input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))

        with torch.no_grad():
            outputs = model(input_ids)
            print(f"‚úì Forward pass successful, output shape: {outputs['logits'].shape}")

        return True
    except Exception as e:
        print(f"‚úó Model test failed: {e}")
        return False


def test_tokenizer():
    """–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞"""
    print("\nTesting tokenizer...")
    try:
        config = ModelConfig()
        tokenizer = MultilingualTokenizer(config)

        # –¢–µ—Å—Ç –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è/–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        test_text = "Hello world! –ü—Ä–∏–≤–µ—Ç –º–∏—Ä!"
        tokens = tokenizer.encode(test_text, 'en')
        decoded = tokenizer.decode(tokens)

        print(f"‚úì Tokenizer created, vocab size: {tokenizer.get_vocab_size()}")
        print(f"‚úì Encoding/decoding test: '{test_text}' -> {len(tokens)} tokens -> '{decoded}'")

        # –¢–µ—Å—Ç –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        batch = tokenizer.encode_batch([test_text], ['en'])
        print(f"‚úì Batch processing test passed")

        return True
    except Exception as e:
        print(f"‚úó Tokenizer test failed: {e}")
        return False


def test_data():
    """–¢–µ—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nTesting data preparation...")
    try:
        config = ModelConfig()
        tokenizer = MultilingualTokenizer(config)

        # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–∞
        dataset = MultilingualDataset(config, tokenizer, split="train")

        if len(dataset) > 0:
            sample = dataset[0]
            print(f"‚úì Dataset created with {len(dataset)} samples")
            print(f"‚úì Sample keys: {list(sample.keys())}")
            print(f"‚úì Sample input shape: {sample['input_ids'].shape}")
        else:
            print("‚ö† Dataset is empty (expected for test environment)")

        return True
    except Exception as e:
        print(f"‚úó Data test failed: {e}")
        return False


def test_evaluator():
    """–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏"""
    print("\nTesting evaluator...")
    try:
        config = ModelConfig()
        model = PrometheusGPT(config)
        tokenizer = MultilingualTokenizer(config)

        evaluator = ModelEvaluator(config, model, tokenizer)
        print("‚úì Evaluator created successfully")

        # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        speed_results = evaluator.benchmark_inference_speed([1], [32])
        print(f"‚úì Inference speed test: {list(speed_results.keys())[0]} = {list(speed_results.values())[0]:.1f}")

        return True
    except Exception as e:
        print(f"‚úó Evaluator test failed: {e}")
        return False


def test_cuda():
    """–¢–µ—Å—Ç CUDA –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏"""
    print("\nTesting CUDA setup...")
    if torch.cuda.is_available():
        device_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        device_name = torch.cuda.get_device_name(current_device)
        memory = torch.cuda.get_device_properties(current_device).total_memory / 1024**3

        print(f"‚úì CUDA available: {device_count} device(s)")
        print(f"‚úì Current device: {current_device} ({device_name})")
        print(f"‚úì GPU memory: {memory:.1f} GB")

        return True
    else:
        print("‚ö† CUDA not available - training will be slow on CPU")
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("=" * 60)
    print("PrometheusGPT Mini - Installation Test")
    print("=" * 60)

    tests = [
        ("Imports", test_imports),
        ("Configuration", test_config),
        ("CUDA Setup", test_cuda),
        ("Model Architecture", test_model),
        ("Tokenizer", test_tokenizer),
        ("Data Preparation", test_data),
        ("Evaluator", test_evaluator),
    ]

    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚úó {test_name} crashed: {e}")
            results.append((test_name, False))

    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 60)
    print("TEST RESULTS SUMMARY")
    print("=" * 60)

    passed = 0
    total = len(results)

    for test_name, result in results:
        status = "‚úì PASS" if result else "‚úó FAIL"
        print("25")
        if result:
            passed += 1

    print(f"\nPassed: {passed}/{total} tests")

    if passed == total:
        print("üéâ All tests passed! PrometheusGPT Mini is ready for training.")
        return 0
    else:
        print("‚ö†Ô∏è  Some tests failed. Please check the errors above.")
        print("   You may still be able to run the model with limited functionality.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
