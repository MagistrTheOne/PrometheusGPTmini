# PrometheusGPT Mini

**Author: MagistrTheOne, Krasnodar, 2025**

–ú–∞–ª–µ–Ω—å–∫–∞—è –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è LLM –º–æ–¥–µ–ª—å (~8M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –∏ –≤–µ—Å–∞–º–∏.

## üöÄ –¶–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞

- –°–æ–∑–¥–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é LLM –º–æ–¥–µ–ª—å —Å –Ω—É–ª—è
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç–∏ (RU/EN –∏ –¥—Ä—É–≥–∏–µ —è–∑—ã–∫–∏)
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è RTX 2080 Super (8GB VRAM)
- –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.10+
- NVIDIA GPU —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è RTX 2080 Super)
- 16GB RAM
- 50GB+ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

- **–¢–∏–ø:** Transformer-based seq2seq –º–æ–¥–µ–ª—å
- **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:** ~8M
- **–°–ª–æ–∏:** 4-6 encoder/decoder —Å–ª–æ–µ–≤
- **–≠–º–±–µ–¥–¥–∏–Ω–≥–∏:** 512 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
- **–í–Ω–∏–º–∞–Ω–∏–µ:** 8 –≥–æ–ª–æ–≤
- **–í—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞:** 256 —Ç–æ–∫–µ–Ω–æ–≤

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
prometheusgpt/
‚îú‚îÄ‚îÄ data/                    # –î–∞—Ç–∞—Å–µ—Ç—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ model/              # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer/          # BPE —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
‚îÇ   ‚îú‚îÄ‚îÄ training/           # –ö–æ–Ω–≤–µ–π–µ—Ä –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ api/                # REST API
‚îú‚îÄ‚îÄ tests/                  # –¢–µ—Å—Ç—ã
‚îú‚îÄ‚îÄ requirements.txt        # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ README.md              # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏
venv\Scripts\activate     # Windows
```

### 3. –ó–∞–ø—É—Å–∫ API

```bash
cd src/api
uvicorn main:app --reload
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è –≤ `src/model/config.py`:
- `vocab_size`: —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è (30k —Ç–æ–∫–µ–Ω–æ–≤)
- `d_model`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (512)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (4-6)
- `n_heads`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è (8)
- `d_ff`: —Ä–∞–∑–º–µ—Ä feed-forward —Å–ª–æ—è (2048)
- `dropout`: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç dropout (0.1)

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–ü—Ä–æ–µ–∫—Ç –≤–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:
- GPU/CPU –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ `psutil`
- –ú–µ—Ç—Ä–∏–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Prometheus
- –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è –∏ inference

## üéØ –°—Ç–∞—Ç—É—Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### ‚úÖ –§–∞–∑–∞ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ - –ó–ê–í–ï–†–®–ï–ù–ê
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞
- –í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Å—Ä–µ–¥–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞
- –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞

### ‚úÖ –§–∞–∑–∞ 2: –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å - –ó–ê–í–ï–†–®–ï–ù–ê
- Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ (~8M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
- BPE —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å—é —Å–æ–∑–¥–∞–Ω
- –î–∞—Ç–∞—Å–µ—Ç —Å –∞–≤—Ç–æ—Ä—Å—Ç–≤–æ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω
- –ö–æ–Ω–≤–µ–π–µ—Ä –æ–±—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ RTX 2080 Super

### ‚úÖ –§–∞–∑–∞ 3: –ì–∏–±—Ä–∏–¥–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è - –ó–ê–í–ï–†–®–ï–ù–ê
- ‚úÖ Gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ (38% reduction)
- ‚úÖ Dynamic attention pruning (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- ‚úÖ –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å training pipeline
- ‚úÖ –¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- seq_len=256, batch_size=16 —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ OOM
- GPU –ø–∞–º—è—Ç—å < 9GB –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- Loss —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è —Å—Ç–∞–±–∏–ª—å–Ω–æ (23.4% reduction)
- –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è/–≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

### ‚úÖ –§–∞–∑–∞ 4: –î–∞—Ç–∞—Å–µ—Ç –∏ –æ–±—É—á–µ–Ω–∏–µ - –ó–ê–í–ï–†–®–ï–ù–ê
- ‚úÖ –°–±–æ—Ä –∏ –æ—á–∏—Å—Ç–∫–∞ RU/EN –∫–æ—Ä–ø—É—Å–∞ (—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç 10k+)
- ‚úÖ BPE —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å —Ä–∞–∑–º–µ—Ä–æ–º —Å–ª–æ–≤–∞—Ä—è 3k (–≥–æ—Ç–æ–≤ –¥–ª—è 30k+)
- ‚úÖ Memory-optimized DataLoader —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- ‚úÖ Advanced training pipeline —Å checkpointing –∏ monitoring
- ‚úÖ Smoke test: 100 —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è —Å decreasing loss

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- Data pipeline: 10k —Ç–µ–∫—Å—Ç–æ–≤ —Å –∞–≤—Ç–æ—Ä—Å–∫–∏–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏
- Tokenizer: 3k —Å–ª–æ–≤–∞—Ä—å —Å –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å—é
- Training: Loss reduction –Ω–∞ –¥–µ–º–æ –¥–∞—Ç–∞—Å–µ—Ç–µ
- Memory: < 5GB per batch (seq_len=256, batch_size=16)
- Checkpoints: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

### üöß –§–∞–∑–∞ 5: –ü—Ä–æ–¥–∞–∫—à–µ–Ω –¥–µ–ø–ª–æ–π
- [ ] REST API —á–µ—Ä–µ–∑ FastAPI —Å streaming
- [ ] Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è —Å CUDA
- [ ] GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏
- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è inference

## üéØ –ü–ª–∞–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è

- [ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π (int8/4bit)
- [ ] –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —è–∑—ã–∫–æ–≤
- [ ] –ì–∏–±—Ä–∏–¥–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (LSTM + Transformer)
- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è inference —Å–∫–æ—Ä–æ—Å—Ç–∏
- [ ] Streaming –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞. –í—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã ¬© MagistrTheOne, 2025

---

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –Ω—É–ª—è –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Å–æ–≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π.
